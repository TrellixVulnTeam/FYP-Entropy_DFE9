{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sqlite3\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Data From DB\")\n",
    "# db must be in same folder as notebook\n",
    "targetDatabase = 'engA.db'\n",
    "con = sqlite3.connect(targetDatabase)\n",
    "db = pd.read_sql_query(\"\"\"SELECT sid, cid, clemma, tag, tags FROM concept\"\"\",con)\n",
    "\n",
    "print(\"Data Loaded!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of db\n",
    "db.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word, how many instances\n",
    "#  for each word instance, list tags\n",
    "#   for each tags, how many times the tag appear in the word\n",
    "\n",
    "def tagsCount(row):\n",
    "    tagsString = row['tags']\n",
    "    if tagsString == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(row['tags'].split(\"; \"))\n",
    "\n",
    "db['tagsCount'] =  db.apply(tagsCount, axis=1)\n",
    "# db.head(20)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = db.groupby('clemma').size()\n",
    "wordsDB = db.drop(['sid', 'cid','tag'], axis = 1)\n",
    "numWords = numWords.to_frame()\n",
    "numWords.reset_index(level=0, inplace=True)\n",
    "numWords.rename(columns={ numWords.columns[0]: \"clemma\" , numWords.columns[1]: 'wordCount'}, inplace = True)\n",
    "numWords.head(5)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTags = db.drop(['clemma','sid', 'cid','tags','tagsCount'], axis = 1)\n",
    "allTags = allTags.drop_duplicates()\n",
    "\n",
    "allWords = db.drop(['tag','sid', 'cid','tags','tagsCount'], axis = 1)\n",
    "allWords = allWords.drop_duplicates()\n",
    "\n",
    "allWordCounts = db.groupby(['clemma']).size()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wordsDB = pd.merge(wordsDB,numWords, on=\"clemma\")\n",
    "wordsDB = wordsDB.drop_duplicates()\n",
    "def stringToList(string):\n",
    "    if string == None:\n",
    "        return []\n",
    "    else:\n",
    "        return string.split('; ')\n",
    "\n",
    "wordsDB['tags'] = wordsDB.apply(lambda x : stringToList(x['tags']), axis =1  )\n",
    "a= wordsDB.groupby(['clemma']).agg({'tags': \"sum\"})\n",
    "a.reset_index(level=0, inplace=True)\n",
    "a['tags'] = a.apply(lambda r: set(r['tags']), axis = 1)\n",
    "a['tagsCount'] = a.apply(lambda r: len(r['tags']), axis = 1)\n",
    "a = a.sort_values(['tagsCount'], ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "tagCount=0\n",
    "\n",
    "def getTagCount(row):\n",
    "    global tagCount\n",
    "    tagCount+=1      \n",
    "    word = row['clemma']\n",
    "    print(word, tagCount*100/len(allWords), \"percent Complete\")\n",
    "    tags = dict.fromkeys(row['tags'], 0)\n",
    "    strippedTags = {}\n",
    "    s = 0\n",
    "    sumTags=0\n",
    "    tags['w'] = 0\n",
    "    tags['x'] = 0\n",
    "    tags['pers'] = 0\n",
    "    for tag in tags.keys():\n",
    "        # TODO: CHANGED HERE\n",
    "        strippedTag = tag.strip()\n",
    "        if tag != strippedTag:\n",
    "            print(f\"'{tag}', '{strippedTag}'\")\n",
    "        count = len(db[ (db['clemma'] == word) & ( db['tag'] == strippedTag) ].index)\n",
    "        strippedTags[strippedTag] = count\n",
    "        sumTags+=count\n",
    "        n = count/allWordCounts[word]\n",
    "        if n == 0:\n",
    "            continue\n",
    "        nlogn = n * math.log10(n)\n",
    "        s += abs(nlogn)\n",
    "\n",
    "    if (s>1):\n",
    "        print(\"ANOMALY!\", word )\n",
    "        print(\"word Count:\",allWordCounts[word], \"tag: \",sumTags )\n",
    "    return (s,strippedTags)\n",
    "\n",
    "b  = a.apply(getTagCount, axis =1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST EXECUTE\n",
    "a[\"results\"] = b\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', 0)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# To check a specific clemma\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', 0)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "a[ (a['clemma'] == \"break\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save results\n",
    "import os\n",
    "print(os.getcwd())\n",
    "p = os.path.join(os.getcwd(), \"PicklepeePumperrump.pckl\")\n",
    "print(p)\n",
    "a.to_pickle(p)\n",
    "# Remember to change name of pckl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read results\n",
    "print(\"Unpickling!\")\n",
    "\n",
    "rdb = pd.read_pickle('2019hg8011_engA_processed.pckl')\n",
    "print(\"Unpickled!\")\n",
    "pd.set_option('display.max_rows', 0)\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "rdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort results\n",
    "rdb['entropyVal'] =  rdb.apply(lambda x: x['results'][0], axis =1)\n",
    "rdb = rdb.sort_values(['entropyVal'],axis = 0, ascending= True )\n",
    "rdb.head(1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdb = rdb.sort_values(['entropyVal'],axis = 0, ascending= False )\n",
    "rdb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel conversion\n",
    "rdb.to_excel(\"output.xlsx\")"
   ]
  }
 ]
}